{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import xobjects as xo\n",
    "import xtrack as xt\n",
    "import xpart as xp\n",
    "import xcoll as xc\n",
    "import scipy\n",
    "import io \n",
    "\n",
    "from IPython import embed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------- LOADING FUNCTIONS ----------------------------\n",
    "\n",
    "\n",
    "def load_colldb_new(filename):\n",
    "    with open(filename, \"r\") as infile:\n",
    "        coll_data_string = \"\"\n",
    "        family_settings = {}\n",
    "        family_types = {}\n",
    "        onesided = {}\n",
    "        tilted = {}\n",
    "        bend = {}\n",
    "        xdim = {}\n",
    "        ydim = {}\n",
    "\n",
    "        for l_no, line in enumerate(infile):\n",
    "            if line.startswith(\"#\"):\n",
    "                continue  # Comment\n",
    "            if len(line.strip()) == 0:\n",
    "                continue  # Empty line\n",
    "            sline = line.split()\n",
    "            if len(sline) < 6 or sline[0].lower() == \"crystal\" or sline[0].lower() == \"target\":\n",
    "                if sline[0].lower() == \"nsig_fam\":\n",
    "                    family_settings[sline[1]] = sline[2]\n",
    "                    family_types[sline[1]] = sline[3]\n",
    "                elif sline[0].lower() == \"onesided\":\n",
    "                    onesided[sline[1]] = int(sline[2])\n",
    "                elif sline[0].lower() == \"tilted\":\n",
    "                    tilted[sline[1]] = [float(sline[2]), float(sline[3])]\n",
    "                elif sline[0].lower() == \"crystal\":\n",
    "                    bend[sline[1]] = float(sline[2])\n",
    "                    xdim[sline[1]] = float(sline[3])\n",
    "                    ydim[sline[1]] = float(sline[4])\n",
    "                elif sline[0].lower() == \"target\":\n",
    "                    xdim[sline[1]] = float(sline[2])\n",
    "                    ydim[sline[1]] = float(sline[3])\n",
    "                elif sline[0].lower() == \"settings\":\n",
    "                    pass  # Acknowledge and ignore this line\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown setting {line}\")\n",
    "            else:\n",
    "                coll_data_string += line\n",
    "\n",
    "    names = [\"name\", \"opening\", \"material\", \"length\", \"angle\", \"offset\"]\n",
    "\n",
    "    df = pd.read_csv(io.StringIO(coll_data_string), delim_whitespace=True,\n",
    "                     index_col=False, skip_blank_lines=True, names=names)\n",
    "\n",
    "    df[\"angle\"] = df[\"angle\"] \n",
    "    df[\"name\"] = df[\"name\"].str.lower() # Make the names lowercase for easy processing\n",
    "    df[\"gap\"] = df[\"opening\"].apply(lambda s: float(family_settings.get(s, s)))\n",
    "    df[\"type\"] = df[\"opening\"].apply(lambda s: family_types.get(s, \"UNKNOWN\"))\n",
    "    df[\"side\"] = df[\"name\"].apply(lambda s: onesided.get(s, 0))\n",
    "    df[\"bend\"] = df[\"name\"].apply(lambda s: bend.get(s, 0))\n",
    "    df[\"xdim\"] = df[\"name\"].apply(lambda s: xdim.get(s, 0))\n",
    "    df[\"ydim\"] = df[\"name\"].apply(lambda s: ydim.get(s, 0))\n",
    "    df[\"tilt_left\"] = df[\"name\"].apply(lambda s: np.deg2rad(tilted.get(s, [0, 0])[0]))\n",
    "    df[\"tilt_right\"] = df[\"name\"].apply(lambda s: np.deg2rad(tilted.get(s, [0, 0])[1]))\n",
    "    df = df.set_index(\"name\").T\n",
    "\n",
    "    # Ensure the collimators marked as one-sided or tilted are actually defined\n",
    "    defined_set = set(df.columns) # The data fram was transposed so columns are names\n",
    "    onesided_set = set(onesided.keys())\n",
    "    tilted_set = set(tilted.keys())\n",
    "    if not onesided_set.issubset(defined_set):\n",
    "        different = onesided_set - defined_set\n",
    "        raise SystemExit('One-sided collimators not defined: {}'.format(\", \".join(different)))\n",
    "    if not tilted_set.issubset(defined_set):\n",
    "        different = tilted_set - defined_set\n",
    "        raise SystemExit('Tilted collimators not defined: {}'.format(\",\".join(different)))\n",
    "    return df.T\n",
    "\n",
    "\n",
    "def find_axis_intercepts(x_coords, y_coords):\n",
    "    x_intercepts = []\n",
    "    y_intercepts = []\n",
    "\n",
    "    for i in range(len(x_coords)):\n",
    "        x1, y1 = x_coords[i], y_coords[i]\n",
    "        x2, y2 = x_coords[(i + 1) % len(x_coords)], y_coords[(i + 1) % len(y_coords)]\n",
    "\n",
    "        if x1 == x2:\n",
    "        # Vertical line, no y-intercept\n",
    "            y_intercept = 0.0 if x1 == x2 == 0.0 else None\n",
    "        else:\n",
    "            slope = (y2 - y1) / (x2 - x1)\n",
    "            y_intercept = y1 - (slope * x1)\n",
    "\n",
    "        if y1 == y2:\n",
    "        # Horizontal line, no x-intercept\n",
    "            x_intercept = 0.0 if y1 == y2 == 0.0 else None\n",
    "        else:\n",
    "            slope = (x2 - x1) / (y2 - y1)\n",
    "            x_intercept = x1 - (slope * y1)\n",
    "\n",
    "        # Check if the x-intercept is within the range of x1 and x2\n",
    "        if x_intercept is not None and (x1 <= x_intercept <= x2 or x2 <= x_intercept <= x1):\n",
    "            x_intercepts.append(x_intercept)\n",
    "\n",
    "        # Check if the y-intercept is within the range of y1 and y2\n",
    "        if y_intercept is not None and (y1 <= y_intercept <= y2 or y2 <= y_intercept <= y1):\n",
    "            y_intercepts.append(y_intercept)\n",
    "\n",
    "    return x_intercepts, y_intercepts\n",
    "\n",
    "\n",
    "\n",
    "def find_bad_offset_apertures(line):\n",
    "    aperture_offsets = {}\n",
    "    for name, element in line.element_dict.items():\n",
    "        if 'offset' in name and element.__class__.__name__.startswith('XYShift'):\n",
    "            aper_name = name.split('_offset')[0]\n",
    "            aperture_offsets[aper_name] = (element.dx, element.dy)\n",
    "\n",
    "    bad_apers = {}\n",
    "    for ap_name, offset in aperture_offsets.items():\n",
    "        aperture_el = line.element_dict[ap_name]\n",
    "\n",
    "        cname= aperture_el.__class__.__name__\n",
    "        ap_dict = aperture_el.to_dict()\n",
    "\n",
    "        if cname == 'LimitEllipse':\n",
    "            x_min = -ap_dict['a']\n",
    "            x_max = ap_dict['a']\n",
    "            y_min = -ap_dict['b']\n",
    "            y_max = ap_dict['b']\n",
    "        elif cname == 'LimitRect':\n",
    "            x_min = ap_dict['min_x']\n",
    "            x_max = ap_dict['max_x']\n",
    "            y_min = ap_dict['min_y']\n",
    "            y_max = ap_dict['max_y']\n",
    "        elif cname == 'LimitRectEllipse':\n",
    "            x_min = -ap_dict['max_x']\n",
    "            x_max = ap_dict['max_x']\n",
    "            y_min = -ap_dict['max_y']\n",
    "            y_max = ap_dict['max_y']\n",
    "        elif cname == 'LimitRacetrack':\n",
    "            x_min = ap_dict['min_x']\n",
    "            x_max = ap_dict['max_x']\n",
    "            y_min = ap_dict['min_y']\n",
    "            y_max = ap_dict['max_y']\n",
    "        elif cname == 'LimitPolygon':\n",
    "            x_intercepts, y_intercepts = find_axis_intercepts(ap_dict['x_vertices'],\n",
    "                                                            ap_dict['y_vertices'])\n",
    "            x_min = min(x_intercepts)\n",
    "            x_max = max(x_intercepts)\n",
    "            y_min = min(y_intercepts)\n",
    "            y_max = max(y_intercepts)\n",
    "\n",
    "        tolerance = 5e-3\n",
    "        \"\"\"if (x_max - offset[0] < tolerance \n",
    "            or -x_min + offset[0] < tolerance \n",
    "            or y_max - offset[1] < tolerance \n",
    "            or -y_min + offset[1] < tolerance):\"\"\"\n",
    "        if (offset[0] -x_max > tolerance \n",
    "            or  -offset[0] + x_min > tolerance \n",
    "            or  offset[1] - y_max > tolerance \n",
    "            or  -offset[1] + y_min > tolerance ):\n",
    "                bad_apers[ap_name] = (x_min, x_max, y_min, y_max, offset[0], offset[1])\n",
    "\n",
    "    return bad_apers\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mode:  target_absorber \n",
      " Seed:  12345 \n",
      "\n",
      "Input files:\n",
      " /afs/cern.ch/work/c/cmaccani/xsuite_sim/twocryst_sim/input_files/HL_IR7_tune_changed/b4_sequence_patched_tune.json \n",
      " /afs/cern.ch/work/c/cmaccani/xsuite_sim/twocryst_sim/input_files/colldbs/CollDB_HL_tight_b4.data \n",
      "\n",
      "\n",
      "Twocryst gaps:   TCCS:  7.2 , TARGET:  33.6 , TCCP: 33.6 , PIXEL: 33.6 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c313eee3f140338a01a1adca60a67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading line from dict:   0%|          | 0/151124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading line from dict.           \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ---------------------------- MAIN ----------------------------\n",
    "\n",
    "\n",
    "config_file = 'config_sim.yaml'\n",
    "\n",
    "with open(config_file, 'r') as stream:\n",
    "    config_dict = yaml.safe_load(stream)\n",
    "\n",
    "# Configure run parameters\n",
    "run_dict = config_dict['run']\n",
    "\n",
    "beam          = run_dict['beam']\n",
    "plane         = run_dict['plane']\n",
    "\n",
    "num_turns     = run_dict['turns']\n",
    "num_particles = run_dict['nparticles']\n",
    "engine        = run_dict['engine']\n",
    "\n",
    "seed          = run_dict['seed']\n",
    "\n",
    "TCCS_align_angle_step = float(run_dict['TCCS_align_angle_step'])\n",
    "\n",
    "normalized_emittance = run_dict['normalized_emittance']\n",
    "\n",
    "mode = run_dict['mode']\n",
    "print('\\nMode: ', mode, '\\n', 'Seed: ', seed, '\\n')\n",
    "\n",
    "save_list = run_dict['save_list']\n",
    "\n",
    "# Setup input files\n",
    "file_dict = config_dict['input_files']\n",
    "\n",
    "coll_file = os.path.expandvars(file_dict['collimators'])\n",
    "line_file = os.path.expandvars(file_dict[f'line_b{beam}'])\n",
    "\n",
    "print('Input files:\\n', line_file, '\\n', coll_file, '\\n')\n",
    "\n",
    "if coll_file.endswith('.yaml'):\n",
    "    with open(coll_file, 'r') as stream:\n",
    "        coll_dict = yaml.safe_load(stream)['collimators']['b'+config_dict['run']['beam']]\n",
    "if coll_file.endswith('.data'):\n",
    "    coll_dict = load_colldb_new(coll_file).to_dict('index')\n",
    "\n",
    "TCCS_gap = float(run_dict['TCCS_gap'])\n",
    "TCCP_gap = float(run_dict['TCCP_gap'])\n",
    "TARGET_gap = float(run_dict['TARGET_gap'])\n",
    "PIXEL_gap = float(run_dict['PIXEL_gap'])\n",
    "\n",
    "\n",
    "print('\\nTwocryst gaps:   TCCS: ', TCCS_gap,', TARGET: ', TARGET_gap , ', TCCP:' ,TCCP_gap ,', PIXEL:' , PIXEL_gap, '\\n')\n",
    "\n",
    "context = xo.ContextCpu(omp_num_threads='auto')\n",
    "\n",
    "# Define output path\n",
    "path_out = Path.cwd() / 'Outputdata'\n",
    "\n",
    "if not path_out.exists():\n",
    "    os.makedirs(path_out)\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------- SETUP LINE ----------------------------\n",
    "\n",
    "# Load from json\n",
    "line = xt.Line.from_json(line_file)\n",
    "\n",
    "end_s = line.get_length()\n",
    "\n",
    "TCCS_name = 'tccs.5r3.b2'\n",
    "TCCP_name = 'tccp.4l3.b2'\n",
    "TARGET_name = 'target.4l3.b2'\n",
    "PIXEL_name = 'pixel.detector'\n",
    "TCP_name = 'tcp.d6r7.b2'\n",
    "\n",
    "d_pix = 1 # [m]\n",
    "\n",
    "TCCS_loc = end_s - 6773.7 #6775\n",
    "TCCP_loc = end_s - 6653.3 #6655\n",
    "TARGET_loc = end_s - (6653.3 + coll_dict[TCCP_name][\"length\"]/2 + coll_dict[TARGET_name][\"length\"]/2+0.0001)\n",
    "PIXEL_loc = end_s - (6653.3 - coll_dict[TCCP_name][\"length\"]/2 - d_pix)\n",
    "TCP_loc = line.get_s_position()[line.element_names.index(TCP_name)]\n",
    "\n",
    "\n",
    "line.insert_element(at_s=TCCS_loc, element=xt.Marker(), name=TCCS_name)\n",
    "line.insert_element(at_s=TCCS_loc, element=xt.LimitEllipse(a_squ=0.0016, b_squ=0.0016, a_b_squ=2.56e-06), name=TCCS_name+'_aper')\n",
    "line.insert_element(at_s=TCCP_loc, element=xt.Marker(), name=TCCP_name)\n",
    "line.insert_element(at_s=TCCP_loc, element=xt.LimitEllipse(a_squ=0.0016, b_squ=0.0016, a_b_squ=2.56e-06), name=TCCP_name+'_aper')\n",
    "line.insert_element(at_s=TARGET_loc, element=xt.Marker(), name=TARGET_name)\n",
    "line.insert_element(at_s=TARGET_loc, element=xt.LimitEllipse(a_squ=0.0016, b_squ=0.0016, a_b_squ=2.56e-06), name= TARGET_name + '_aper')\n",
    "line.insert_element(at_s=PIXEL_loc, element=xt.Marker(), name=PIXEL_name)\n",
    "#line.insert_element(at_s=PIXEL_loc, element=xt.LimitEllipse(a_squ=0.0016, b_squ=0.0016, a_b_squ=2.56e-06), name= PIXEL_name + '_aper')\n",
    "\n",
    "\n",
    "TCCS_monitor = xt.ParticlesMonitor(num_particles=num_particles, start_at_turn=0, stop_at_turn=num_turns)\n",
    "TARGET_monitor = xt.ParticlesMonitor(num_particles=num_particles, start_at_turn=0, stop_at_turn=num_turns)\n",
    "PIXEL_monitor = xt.ParticlesMonitor(num_particles=num_particles, start_at_turn=0, stop_at_turn=num_turns)\n",
    "TCP_monitor = xt.ParticlesMonitor(num_particles=num_particles, start_at_turn=0, stop_at_turn=num_turns)\n",
    "dx = 1e-11\n",
    "line.insert_element(at_s = TCCS_loc - coll_dict[TCCS_name][\"length\"]/2 - dx, element=TCCS_monitor, name='TCCS_monitor')\n",
    "line.insert_element(at_s = TARGET_loc - coll_dict[TARGET_name][\"length\"]/2 - dx, element=TARGET_monitor, name='TARGET_monitor')\n",
    "line.insert_element(at_s = PIXEL_loc, element=PIXEL_monitor, name='PIXEL_monitor')\n",
    "#line.insert_element(at_s = TCP_loc + coll_dict[TCP_name]/2 + dx, element=TCP_monitor, name='TCP_monitor')\n",
    "\n",
    "\n",
    "bad_aper = find_bad_offset_apertures(line)\n",
    "print('Bad apertures : ', bad_aper)\n",
    "print('Replace bad apertures with Marker')\n",
    "for name in bad_aper.keys():\n",
    "    line.element_dict[name] = xt.Marker()\n",
    "    print(name, line.get_s_position(name), line.element_dict[name])\n",
    "\n",
    "# Aperture model check\n",
    "print('\\nAperture model check on imported model:')\n",
    "df_imported = line.check_aperture()\n",
    "assert not np.any(df_imported.has_aperture_problem)\n",
    "\n",
    "\n",
    "# Initialise collmanager\n",
    "if coll_file.endswith('.yaml'):\n",
    "    coll_manager = xc.CollimatorManager.from_yaml(coll_file, line=line, beam=beam, _context=context, ignore_crystals=False)\n",
    "elif coll_file.endswith('.data'):\n",
    "    coll_manager = xc.CollimatorManager.from_SixTrack(coll_file, line=line, _context=context, ignore_crystals=False, nemitt_x = normalized_emittance,  nemitt_y = normalized_emittance, beam=beam)\n",
    "    # switch on cavities\n",
    "    speed = line.particle_ref._xobject.beta0[0]*scipy.constants.c\n",
    "    harmonic_number = 35640\n",
    "    voltage = 12e6/len(line.get_elements_of_type(xt.Cavity)[1])\n",
    "    frequency = harmonic_number * speed /line.get_length()\n",
    "    for side in ['l', 'r']:\n",
    "        for cell in ['a','b','c','d']:\n",
    "            line[f'acsca.{cell}5{side}4.b2'].voltage = voltage\n",
    "            line[f'acsca.{cell}5{side}4.b2'].frequency = frequency\n",
    "\n",
    "\n",
    "line.to_json('./input_files/HL_twocryst.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Install collimators into line\n",
    "if engine == 'everest':\n",
    "    coll_names = coll_manager.collimator_names\n",
    "\n",
    "    if mode == 'target_absorber': \n",
    "        black_absorbers = [TARGET_name,]\n",
    "    else: \n",
    "        black_absorbers = []\n",
    "\n",
    "    everest_colls = [name for name in coll_names if name not in black_absorbers]\n",
    "\n",
    "    coll_manager.install_everest_collimators(names=everest_colls,verbose=True)\n",
    "    coll_manager.install_black_absorbers(names = black_absorbers, verbose=True)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown scattering engine {engine}!\")\n",
    "\n",
    "\n",
    "# Aperture model check\n",
    "print('\\nAperture model check after introducing collimators:')\n",
    "df_with_coll = line.check_aperture()\n",
    "assert not np.any(df_with_coll.has_aperture_problem)\n",
    "\n",
    "    \n",
    "# Build the tracker\n",
    "#coll_manager.build_tracker()\n",
    "coll_manager.build_tracker()\n",
    "\n",
    "# Set the collimator openings based on the colldb,\n",
    "# or manually override with the option gaps={collname: gap}\n",
    "#coll_manager.set_openings()\n",
    "coll_manager.set_openings(gaps = {TCCS_name: TCCS_gap, TCCP_name: TCCP_gap, TARGET_name: TARGET_gap})\n",
    "\n",
    "\n",
    "print(\"\\nTCCS aligned to beam: \", line[TCCS_name].align_angle)\n",
    "#line[TTCS_name].align_angle = TTCS_align_angle_step\n",
    "print(\"TCCS align angle incremented by step: \", TCCS_align_angle_step)\n",
    "line[TCCS_name].align_angle = line[TCCS_name].align_angle + TCCS_align_angle_step\n",
    "print(\"TCCS final alignment angle: \", line[TCCS_name].align_angle)\n",
    "\n",
    "\n",
    "# Aperture model check\n",
    "print('\\nAperture model check after introducing collimators:')\n",
    "df_with_coll = line.check_aperture()\n",
    "assert not np.any(df_with_coll.has_aperture_problem)\n",
    "\n",
    "# Printout useful informations\n",
    "idx_TCCS = line.element_names.index(TCCS_name)\n",
    "idx_TARGET = line.element_names.index(TARGET_name)\n",
    "idx_TCCP = line.element_names.index(TCCP_name)\n",
    "idx_PIXEL = line.element_names.index(PIXEL_name)\n",
    "\n",
    "tw = line.twiss()\n",
    "beta_y_TCCS = tw[:,TCCS_name]['bety'][0]\n",
    "beta_y_TCCP = tw[:,TCCP_name]['bety'][0]\n",
    "beta_y_TARGET = tw[:,TARGET_name]['bety'][0]\n",
    "beta_y_PIXEL = tw[:,PIXEL_name]['bety'][0]\n",
    "beta_rel = line.particle_ref._xobject.beta0[0]\n",
    "gamma = line.particle_ref._xobject.gamma0[0]\n",
    "\n",
    "emittance_phy = normalized_emittance/(beta_rel*gamma)\n",
    "\n",
    "sigma_TCCS = np.sqrt(emittance_phy*beta_y_TCCS)\n",
    "sigma_TCCP = np.sqrt(emittance_phy*beta_y_TCCP)\n",
    "sigma_TARGET = np.sqrt(emittance_phy*beta_y_TARGET)\n",
    "sigma_PIXEL = np.sqrt(emittance_phy*beta_y_PIXEL)\n",
    "\n",
    "print(f\"\\nTCCS\\nCrystalAnalysis(n_sigma={line.elements[idx_TCCS].jaw_L/sigma_TCCS}, length={ coll_dict[ TCCS_name]['length']}, ydim={ coll_dict[ TCCS_name]['xdim']}, xdim={ coll_dict[ TCCS_name]['ydim']}, bend={ coll_dict[ TCCS_name]['bend']}, align_angle={ line.elements[idx_TCCS].align_angle}, sigma={sigma_TCCS})\")\n",
    "print(f\"TARGET\\nTargetAnalysis(n_sigma={line.elements[idx_TARGET].jaw_L/sigma_TARGET}, length={ coll_dict[ TARGET_name]['length']}, ydim={ coll_dict[ TARGET_name]['xdim']}, xdim={ coll_dict[ TARGET_name]['ydim']}, sigma={sigma_TARGET})\")\n",
    "print(f\"TCCP\\nCrystalAnalysis(n_sigma={line.elements[idx_TCCP].jaw_L/sigma_TCCP}, length={ coll_dict[ TCCP_name]['length']}, ydim={ coll_dict[ TCCP_name]['xdim']}, xdim={ coll_dict[ TCCP_name]['ydim']}, bend={ coll_dict[ TCCP_name]['bend']}, sigma={sigma_TCCP})\")\n",
    "print(f\"PIXEL\\nTargetAnalysis(n_sigma={line.elements[idx_TCCP].jaw_L/sigma_TCCP}, length={0}, ydim={0}, xdim={0}, sigma={sigma_PIXEL})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EverestCollimator(inactive_front=0.0, active_length=0.6, inactive_back=0.0, jaw_L=0.0022989302491263903, jaw_R=-0.0022989302491263903, ref_x=4.910024205232376e-06, ref_y=8.480175699409359e-07, sin_zL=1.0, cos_zL=6.123233995736766e-17, sin_zR=1.0, cos_zR=6.123233995736766e-17, sin_yL=0.0, cos_yL=1.0, tan_yL=1.0, sin_yR=0.0, cos_yR=1.0, tan_yR=1.0, _side=0, active=1, _internal_record_id=RecordIdentifier(buffer_id=0, offset=0), _material=Material(Z=6.65, A=13.53, density=2.5, excitation_energy=8.71e-08, nuclear_radius=0.25, nuclear_elastic_slope=76.7, cross_section=[3.62e-01 2.47e-01 0.00e+00 0.00e+00 0.00e+00 9.40e-05], hcut=0.02, name=MolybdenumGraphite, radiation_length=0.1193), rutherford_rng=RandomRutherford(lower_val=0.0009982, upper_val=0.02, A=0.0012280392539122623, B=53.50625, Newton_iterations=7), _tracking=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line[TCP_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EverestCrystal(inactive_front=0.0, active_length=0.004, inactive_back=0.0, jaw_L=0.002023846744961569, jaw_R=-0.025, ref_x=-3.8140465516383823e-06, ref_y=-3.550398552456167e-08, sin_zL=1.0, cos_zL=6.123233995736766e-17, sin_zR=1.0, cos_zR=6.123233995736766e-17, sin_yL=0.0, cos_yL=1.0, tan_yL=1.0, sin_yR=0.0, cos_yR=1.0, tan_yR=1.0, _side=1, active=1, _internal_record_id=RecordIdentifier(buffer_id=0, offset=0), align_angle=-1.6117913846552086e-05, bend=80.0, xdim=0.002, ydim=0.035, thick=0.0, miscut=0.0, _orient=1, _material=CrystalMaterial(Z=14.0, A=28.08, density=2.33, excitation_energy=1.73e-07, nuclear_radius=0.441, nuclear_elastic_slope=120.14, cross_section=[6.64e-01 4.30e-01 0.00e+00 0.00e+00 0.00e+00 3.90e-04], hcut=0.02, name=Silicon, crystal_radiation_length=0.0937, crystal_nuclear_length=0.4652, crystal_plane_distance=9.6e-08, crystal_potential=21.34, nuclear_collision_length=0.3016), rutherford_rng=RandomRutherford(lower_val=0.0009982, upper_val=0.02, A=0.0016160247264725453, B=166.49518410000002, Newton_iterations=7), _tracking=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line[TCCS_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "line.to_json('HL_twocryst.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455c0cd2ccfd4750bbc0fdc75efc2aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading line from dict:   0%|          | 0/150839 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'EverestCollimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/cmaccani/ipykernel_135737/1684811308.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HL_twocryst.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/afs/cern.ch/user/c/cmaccani/xsuite/xtrack/xtrack/line.py\u001b[0m in \u001b[0;36mfrom_json\u001b[0;34m(cls, file, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mdct_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdct_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cern.ch/user/c/cmaccani/xsuite/xtrack/xtrack/line.py\u001b[0m in \u001b[0;36mfrom_dict\u001b[0;34m(cls, dct, _context, _buffer, classes)\u001b[0m\n\u001b[1;32m    180\u001b[0m             for ii, (kk, ee) in enumerate(\n\u001b[1;32m    181\u001b[0m                     progress(dct['elements'].items(), desc='Loading line from dict')):\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0melements\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mee\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'elements'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0melements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cern.ch/user/c/cmaccani/xsuite/xtrack/xtrack/line.py\u001b[0m in \u001b[0;36m_deserialize_element\u001b[0;34m(el, class_dict, _buffer)\u001b[0m\n\u001b[1;32m   3701\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_deserialize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3702\u001b[0m     \u001b[0meldct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3703\u001b[0;31m     \u001b[0meltype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meldct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__class__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3704\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meltype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_XoStruct'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3705\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0meltype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meldct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_buffer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'EverestCollimator'"
     ]
    }
   ],
   "source": [
    "new_line = xt.Line.from_json('HL_twocryst.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LCG view 104 + venv",
   "language": "python-custom",
   "name": "lcg-view"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python-custom",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
